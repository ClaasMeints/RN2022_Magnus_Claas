% Encoding: UTF-8

@InProceedings{Dokic2020,
  author    = {Dokic, Kristian},
  booktitle = {Image and Signal Processing},
  title     = {Microcontrollers on the Edge -- Is ESP32 with Camera Ready for Machine Learning?},
  year      = {2020},
  address   = {Cham},
  editor    = {El Moataz, Abderrahim and Mammass, Driss and Mansouri, Alamin and Nouboud, Fathallah},
  pages     = {213--220},
  publisher = {Springer International Publishing},
  abstract  = {For most machine learning tasks big computing power is needed, but some tasks can be done with microcontrollers. In this paper well-known SoC ESP32 has been analyzed. It is usually used in IoT devices for data measurement, but some authors started to use simple machine learning algorithms with them. Generally, this paper will analyze the possibility of using ESP32 with a built-in camera for machine learning algorithms. Focus of research will be on durations of photographing and photograph processing, because that can be a bottleneck of a machine learning tasks.},
  isbn      = {978-3-030-51935-3},
}

@InProceedings{Pareigis2021,
  author    = {Pareigis, Stephan and Tiedemann, Tim and Kasten, Markus and Stehr, Morten and Schnirpel, Thorben and Schwalb, Luk and Burau, Henri},
  booktitle = {Echtzeit 2020},
  title     = {K{\"u}nstliche Intelligenz in der Miniaturautonomie},
  year      = {2021},
  address   = {Wiesbaden},
  editor    = {Unger, Herwig},
  pages     = {41--50},
  publisher = {Springer Fachmedien Wiesbaden},
  abstract  = {Unter den Methoden der k{\"u}nstlichen Intelligenz dominieren in den vergangenen Jahrzehnten die maschinellen Lernverfahren (ML) die Ver{\"o}ffentlichungen. Diese basieren wesentlich auf den zugrundeliegenden Daten. Autonome Miniatursysteme schaffen zug{\"a}ngliche M{\"o}glichkeiten, Daten im realistischen Umfeld zu erzeugen. Auf einem Modell-Frachtschiff im Ma{\ss}stab 1:100 werden Umgebungsdaten gesammelt, die zum autonomen Betrieb herangezogen werden. Auf einem Lastwagen im Ma{\ss}stab 1:87 werden Kameradaten in einer Modellumgebung gesammelt, welche f{\"u}r ML-Methoden genutzt werden. Auf diesen Daten k{\"o}nnen auf getrennter Hardware klassische Autonomieverfahren getestet und weiterentwickelt werden. Ein weitergehendes Ziel ist eine Autonomie auf den Miniaturfahrzeugen selbst. Dies ben{\"o}tigt ganz neue Verfahren der sogenannten Miniaturautonomie. Der aktuelle Stand der Laboraufbauten und die wissenschaftlichen Ziele werden beschrieben.},
  isbn      = {978-3-658-32818-4},
}

@Legislation{NKlimaG,
  author    = {},
  title     = {Niedersächsisches Gesetz zur Förderung des Klimaschutzes und zur Minderung der Folgen des Klimawandels (Niedersächsisches Klimagesetz - NKlimaG) Vom 10. Dezember 2020}
}

@Conference{WirtschaftundEnergieBMWi2019,
  author = {Bundesministerium für Wirtschaft und Energie (BMWi)},
  title  = {Abschlussbericht der Kommission „Wachstum, Strukturwandel und Beschäftigung“},
  year   = {2019},
}

@INPROCEEDINGS{Michalski90researchin,
  author = {Ryszard S. Michalski and Yves Kodratoff},
  title = {Research in Machine Learning: Recent Progress, Classification of Methods and Future Directions},
  booktitle = {},
  year = {1990},
  pages = {3--30},
  publisher = {Morgan Kaufmann}
}

@Inbook{Richter2019_9,
  author="Richter, Stefan",
  title="Unsupervised Learning: Bestimmung von Repr{\"a}sentanten",
  bookTitle="Statistisches und maschinelles Lernen: G{\"a}ngige Verfahren im {\"U}berblick",
  year="2019",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="289--313",
  abstract="In diesem und dem folgenden Kapitel wird das Paradigma des Unsupervised Learning betrachtet. Im Gegensatz zum Supervised Learning werden hier nur noch Realisierungen des feature-Vektors X beobachtet, jedoch kein zugeh{\"o}riges Y. Zu Beginn des Kapitels werden zun{\"a}chst zwei m{\"o}gliche Ziele des Unsupervised Learning formuliert. Das restliche Kapitel setzt sich dann mit dem ersten Ziel, dem Finden von m{\"o}glichst sinnvollen Repr{\"a}sentanten der Trainingsdaten auseinander. Dies erm{\"o}glicht die Aufteilung der Daten in eine bestimmte, vorher vorgegebene Anzahl von Gruppen (Cluster). Es werden zwei Verfahren betrachtet, das k-means-Clustering und das Clustering mit Mischungsverteilungen. F{\"u}r beide werden sowohl Motivation, Modellannahmen, praktische Beispiele und theoretische Resultate diskutiert. Beim Clustering mit Mischungsverteilungen wird der sogenannte EM-Algorithmus eingef{\"u}hrt, der in vielen weiteren Praxisbeispielen Anwendung findet.",
  isbn="978-3-662-59354-7",
  doi="10.1007/978-3-662-59354-7_9",
  url="https://doi.org/10.1007/978-3-662-59354-7_9"
}

@Inbook{Richter2019_1,
author="Richter, Stefan",
title="Supervised Learning: Grundlagen",
bookTitle="Statistisches und maschinelles Lernen: G{\"a}ngige Verfahren im {\"U}berblick",
year="2019",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--24",
abstract="Das Kapitel f{\"u}hrt die Problemstellung des Supervised Learning zun{\"a}chst anhand von allt{\"a}glichen Beispielen ein. Danach erfolgt schrittweise ein {\"U}bergang zu einer formalen Ausdrucksweise mit Hilfe der statistischen Entscheidungstheorie. L{\"o}sungen von Problemen des Supervised Learning sind durch sogenannte Algorithmen gegeben; einige Standardmethoden zur Ermittlung sowie die Untersuchung von deren Qualit{\"a}t in der Praxis werden am Ende des Kapitels besprochen. Der Stoff des Kapitels ist allgemein gehalten und enth{\"a}lt noch keine konkreten Modellannahmen und dazugeh{\"o}rigen Algorithmen.",
isbn="978-3-662-59354-7",
doi="10.1007/978-3-662-59354-7_1",
url="https://doi.org/10.1007/978-3-662-59354-7_1"
}

@Inbook{Ertel2016,
author="Ertel, Wolfgang",
title="Maschinelles Lernen und Data Mining",
bookTitle="Grundkurs K{\"u}nstliche Intelligenz: Eine praxisorientierte Einf{\"u}hrung",
year="2016",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="191--264",
abstract="Definiert man den Begriff der KI wie im Buch von Elaine Rich Ric83Artificial Intelligence is the study of how to make computers do things at which, at the moment, people are better.und bedenkt, dass die Computer uns Menschen insbesondere bez{\"u}glich der Lernf{\"a}higkeit weit unterlegen sind, dann folgt daraus, dass die Erforschung der Mechanismen des Lernens und die Entwicklung maschineller Lernverfahren eines der wichtigsten Teilgebiete der KI darstellt.",
isbn="978-3-658-13549-2",
doi="10.1007/978-3-658-13549-2_8",
url="https://doi.org/10.1007/978-3-658-13549-2_8"
}

@Inbook{Goodfellow-et-al-2016-5,
    title={Machine Learning Basics},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    bootitle={Deep Learning},
    year={2016},
    pages={96--152},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@Inbook{Goodfellow-et-al-2016-6,
    title={Deep Feedforward Networks},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    bootitle={Deep Learning},
    year={2016},
    pages={164--223},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@Inbook{Kossen2019,
author="Kossen, Jannik
and M{\"u}ller, Maike Elisa",
editor="Kersting, Kristian
and Lampert, Christoph
and Rothkopf, Constantin",
title="Lineare Regression",
bookTitle="Wie Maschinen lernen: K{\"u}nstliche Intelligenz verst{\"a}ndlich erkl{\"a}rt",
year="2019",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="61--67",
abstract="Lisa wei{\ss} immer noch nicht, wie schwer das Tier ist, dessen Fu{\ss}abdruck sie in Kap. 5entdeckt hat. Nun l{\"o}st sie das Problem mit einer linearen Regression. Diese ist eine der grundlegendsten Methoden des maschinellen Lernens und hilft Lisa schlussendlich, abzusch{\"a}tzen, wie schwer nun das Tier mit dem gro{\ss}en Fu{\ss}abdruck ungef{\"a}hr ist.",
isbn="978-3-658-26763-6",
doi="10.1007/978-3-658-26763-6_8",
url="https://doi.org/10.1007/978-3-658-26763-6_8"
}

@Inbook{Böttcher2019-22,
author="B{\"o}ttcher, Wolfgang
and Bunne, Charlotte
and von Stetten, Johannes",
editor="Kersting, Kristian
and Lampert, Christoph
and Rothkopf, Constantin",
title="Gradientenabstiegsverfahren",
bookTitle="Wie Maschinen lernen: K{\"u}nstliche Intelligenz verst{\"a}ndlich erkl{\"a}rt",
year="2019",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="171--180",
abstract="Lisa merkt, wie aufwendig es ist, die Algorithmen richtig einzustellen, und sucht nach den perfekten Parametern. Ihr f{\"a}llt auf, dass sie ein {\"a}hnliches Problem bei ihrer letzten Wanderung hatte, und entdeckt das Prinzip der Gradientenabstiegsverfahren.",
isbn="978-3-658-26763-6",
doi="10.1007/978-3-658-26763-6_22",
url="https://doi.org/10.1007/978-3-658-26763-6_22"
}

@Inbook{James2013-2,
author="James, Gareth
and Witten, Daniela
and Hastie, Trevor
and Tibshirani, Robert",
title="Statistical Learning",
bookTitle="An Introduction to Statistical Learning: with Applications in R",
year="2013",
publisher="Springer New York",
address="New York, NY",
pages="15--57",
abstract="In order to motivate our study of statistical learning, we begin with a simple example. Suppose that we are statistical consultants hired by a client to provide advice on how to improve sales of a particular product. The Advertising data set consists of the sales of that product in 200 different markets, along with advertising budgets for the product in each of those markets for three different media: TV, radio, and newspaper.",
isbn="978-1-4614-7138-7",
doi="10.1007/978-1-4614-7138-7_2",
url="https://doi.org/10.1007/978-1-4614-7138-7_2"
}

@Inbook{James2013-12,
author="James, Gareth
and Witten, Daniela
and Hastie, Trevor
and Tibshirani, Robert",
title="Unsupervised Learning",
bookTitle="An Introduction to Statistical Learning: with Applications in R",
year="2013",
publisher="Springer New York",
address="New York, NY",
pages="373--418",
abstract="Most of this book concerns supervised learning methods such as regression and classification. In the supervised learning setting, we typically have access to a set of p features {\$}{\$}X{\_}{\{}1{\}},X{\_}{\{}2{\}},{\backslash}ldots,X{\_}{\{}p{\}}{\$}{\$}, measured on n observations, and a response Y also measured on those same n observations. The goal is then to predict Y using {\$}{\$}X{\_}{\{}1{\}},X{\_}{\{}2{\}},{\backslash}ldots,X{\_}{\{}p{\}}{\$}{\$}.",
isbn="978-1-4614-7138-7",
doi="10.1007/978-1-4614-7138-7_10",
url="https://doi.org/10.1007/978-1-4614-7138-7_10"
}

@InProceedings{GradientDescent,
author="Pierrot, Thomas
and Perrin-Gilbert, Nicolas
and Sigaud, Olivier",
editor="Farka{\v{s}}, Igor
and Masulli, Paolo
and Otte, Sebastian
and Wermter, Stefan",
title="First-Order and Second-Order Variants of the Gradient Descent in a Unified Framework",
booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2021",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="197--208",
abstract="In this paper, we provide an overview of first-order and second-order variants of the gradient descent method that are commonly used in machine learning. We propose a general framework in which 6 of these variants can be interpreted as different instances of the same approach. They are the vanilla gradient descent, the classical and generalized Gauss-Newton methods, the natural gradient descent method, the gradient covariance matrix approach, and Newton's method. Besides interpreting these methods within a single framework, we explain their specificities and show under which conditions some of them coincide.",
isbn="978-3-030-86340-1"
}

@Inbook{Süße2014-2,
author="S{\"u}{\ss}e, Herbert
and Rodner, Erik",
title="Visuelle Erkennungsaufgaben",
bookTitle="Bildverarbeitung und Objekterkennung: Computer Vision in Industrie und Medizin",
year="2014",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="589--613",
abstract="Im nachfolgenden Kapitel werden wir beispielhaft ein paar Verfahren der visuellen Objekterkennung kennenlernen. Dabei handelt es sich oft um eine Kombination einer Merkmalsberechnung und eines Klassifikationsverfahrens. Das Gebiet der Objekterkennung z{\"a}hlt zu den aktivsten Forschungsbereichen in der Bildverarbeitung. Daher werden im Rahmen dieses Buches auch nur wichtige Grundprinzipien erl{\"a}utert, welche in aktuellen Methoden Verwendung finden.",
isbn="978-3-8348-2606-0",
doi="10.1007/978-3-8348-2606-0_20",
url="https://doi.org/10.1007/978-3-8348-2606-0_20"
}

@Inbook{Livshin2022,
author="Livshin, Igor",
title="Internal Mechanics of Neural Network Processing",
bookTitle="Artificial Neural Networks with Java: Tools for Building Neural Network Applications",
year="2022",
publisher="Apress",
address="Berkeley, CA",
pages="9--19",
abstract="This chapter discusses the inner workings of neural network processing. It shows how a network is built, trained, and tested.",
isbn="978-1-4842-7368-5",
doi="10.1007/978-1-4842-7368-5_2",
url="https://doi.org/10.1007/978-1-4842-7368-5_2"
}

@Inbook{Pang2019-2,
author="Pang, Yanwei
and Cao, Jiale",
editor="Jiang, Xiaoyue
and Hadid, Abdenour
and Pang, Yanwei
and Granger, Eric
and Feng, Xiaoyi",
title="Deep Learning in Object Detection",
bookTitle="Deep Learning in Object Detection and Recognition",
year="2019",
publisher="Springer Singapore",
address="Singapore",
pages="19--57",
abstract="Object detection is an important research area in image processing and computer vision. The performance of object detection has significantly improved through applying deep learning technology. Among these methods, convolutional neural network (CNN)-based methods are most frequently used. CNN methods mainly include two classes: two-stage methods and one-stage methods. This chapter firstly introduces some typical CNN-based architectures in details. After that, pedestrian detection, as a classical subset of object detection, is further introduced. According to whether CNN is used or not, pedestrian detection can be divided into two types: handcrafted feature-based methods and CNN-based methods. Among these methods, NNNF (non-neighboring and neighboring features) inspired by pedestrian attributes (i.e., appearance constancy and shape symmetry) and MCF based on handcrafted channels and each layer of CNN are specifically illustrated. Finally, some challenges of object detection (i.e., scale variation, occlusion, and deformation) will be discussed.",
isbn="978-981-10-5152-4",
doi="10.1007/978-981-10-5152-4_2",
url="https://doi.org/10.1007/978-981-10-5152-4_2"
}

@Inbook{Xia2019,
author="Xia, Zhaoqiang",
editor="Jiang, Xiaoyue
and Hadid, Abdenour
and Pang, Yanwei
and Granger, Eric
and Feng, Xiaoyi",
title="An Overview of Deep Learning",
bookTitle="Deep Learning in Object Detection and Recognition",
year="2019",
publisher="Springer Singapore",
address="Singapore",
pages="1--18",
abstract="In the last decade, deep learning has attracted much attention and becomes a dominant technology in artificial intelligence community. This chapter reviews the concepts, methods, and latest applications of deep learning. Firstly, the basic concepts and developing history of deep learning are revisited briefly. Then, five basic types of deep learning methods, i.e., stacked autoencoders, deep belief networks, convolutional neural networks, recurrent neural networks, and generative adversarial networks, are introduced according to applications of deep learning in other domains that are briefly illustrated based on the types of data, such as acoustic data, image data, and textual data. Finally, several issues facing by deep learning are discussed to conclude the trends.",
isbn="978-981-10-5152-4",
doi="10.1007/978-981-10-5152-4_1",
url="https://doi.org/10.1007/978-981-10-5152-4_1"
}

@Inbook{James2021-10,
author="James, Gareth
and Witten, Daniela
and Hastie, Trevor
and Tibshirani, Robert",
title="Deep Learning",
bookTitle="An Introduction to Statistical Learning: with Applications in R",
year="2021",
publisher="Springer US",
address="New York, NY",
pages="403--460",
abstract="This chapter covers the important topic of deep learning. At the time of writing (2020), deep learning is a very active area of research in the machine learning and artificial intelligence communities.",
isbn="978-1-0716-1418-1",
doi="10.1007/978-1-0716-1418-1_10",
url="https://doi.org/10.1007/978-1-0716-1418-1_10"
}

@Inbook{Xiao2021,
author="Xiao, Cao
and Sun, Jimeng",
title="Convolutional Neural Networks (CNN)",
bookTitle="Introduction to Deep Learning for Healthcare",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="83--109",
abstract="Convolutional neural networks (CNN or ConvNet) are a specific type of neural networks for processing grid-like data such as images and time series. In healthcare applications, the CNN models are widely used in automatic feature learning and disease classification from medical images, for example, automatic classification of skin lesions, detection of diabetic retinopathy, and COVID X-ray classification.",
isbn="978-3-030-82184-5",
doi="10.1007/978-3-030-82184-5_6",
url="https://doi.org/10.1007/978-3-030-82184-5_6"
}

@InProceedings{Chen2021,
author="Chen, Chen
and Chen, Wanmi
and Zhou, Sike",
editor="Han, Qinglong
and McLoone, Sean
and Peng, Chen
and Zhang, Baolin",
title="Object Detection of Basketball Robot Based on MobileNet-SSD",
booktitle="Intelligent Equipment, Robots, and Vehicles",
year="2021",
publisher="Springer Singapore",
address="Singapore",
pages="11--22",
abstract="Object detection is one of the research hotspots in the field of computer vision. In this paper, we use the lightweight network MobileNet combined with Single Shot Multibox Detector (SSD) to realize the object detection of the robot. SSD combined with MobileNet can effectively compress the size of the network model and improve the detection rate. The method does automatic extraction on the image features first, and add different size feature maps after the basic network, and then do convolution filtering on the multi dimension feature maps to get the object coordinate value and the object category. In the experiment, compared with the original vision method based on OpenCV, the MobileNet-SSD algorithm was less affected by illumination conditions in the object recognition process, and achieved the rapid and accurate recognition of the basketball robot on the ball.",
isbn="978-981-16-7213-2"
}

@online{TFODAPI,
  author = {Lyudmil Vladimirov},
  title = {Training Custom Object Detector},
  year = 2020,
  url = {https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html},
  urldate = {2021-12-03}
}

@book{warden2020tinyml,
  title={TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-low-power Microcontrollers},
  author={Warden, P. and Situnayake, D.},
  isbn={9781492052043},
  lccn={2020277178},
  url={https://books.google.de/books?id=sB3mxQEACAAJ},
  year={2020},
  publisher={O'Reilly}
}

@Inbook{Currie2021,
author="Currie, Edward H.",
title="Introduction to Embedded System",
bookTitle="Mixed-Signal Embedded Systems Design: A Hands-on Guide to the Cypress PSoC",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="1--34",
abstract="This chapter provides a brief review of the history of embedded systems, microprocessors and microcontrollers. Also presented are basic concepts of programmable logic devices, overviews of the 8051 microcontroller, brief descriptions of some of the more popular and currently available microcontrollers that are in widespread use and introductions to a number of subjects related to microcontrollers and embedded systems, e.g., types of feedback systems employed in embedded systems, microcontroller subsystems, microprocessor/microcontroller memory types, embedded system performance criteria, interrupts, introductory sampling topics, etc.",
isbn="978-3-030-70312-7",
doi="10.1007/978-3-030-70312-7_1",
url="https://doi.org/10.1007/978-3-030-70312-7_1"
}

@online{TFLITE,
  author = {tensorflow.org},
  title = {TensorFlow Lite},
  year = 2021,
  url = {https://www.tensorflow.org/lite/guide},
  urldate = {2021-12-04}
}

@InProceedings{Quant,
author="Fang, Jun
and Shafiee, Ali
and Abdel-Aziz, Hamzah
and Thorsley, David
and Georgiadis, Georgios
and Hassoun, Joseph H.",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Post-training Piecewise Linear Quantization for Deep Neural Networks",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="69--86",
abstract="Quantization plays an important role in the energy-efficient deployment of deep neural networks on resource-limited devices. Post-training quantization is highly desirable since it does not require retraining or access to the full training dataset. The well-established uniform scheme for post-training quantization achieves satisfactory results by converting neural networks from full-precision to 8-bit fixed-point integers. However, it suffers from significant performance degradation when quantizing to lower bit-widths. In this paper, we propose a piecewise linear quantization (PWLQ) scheme (Code will be made available at https://github.com/jun-fang/PWLQ) to enable accurate approximation for tensor values that have bell-shaped distributions with long tails. Our approach breaks the entire quantization range into non-overlapping regions for each tensor, with each region being assigned an equal number of quantization levels. Optimal breakpoints that divide the entire range are found by minimizing the quantization error. Compared to state-of-the-art post-training quantization methods, experimental results show that our proposed method achieves superior performance on image classification, semantic segmentation, and object detection with minor overhead.",
isbn="978-3-030-58536-5"
}

@InProceedings{Prune,
author="He, Wei
and Huang, Zhongzhan
and Liang, Mingfu
and Liang, Senwei
and Yang, Haizhao",
editor="Farka{\v{s}}, Igor
and Masulli, Paolo
and Otte, Sebastian
and Wermter, Stefan",
title="Blending Pruning Criteria for Convolutional Neural Networks",
booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2021",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="3--15",
abstract="The advancement of convolutional neural networks (CNNs) on various vision applications has attracted lots of attention. Yet the majority of CNNs are unable to satisfy the strict requirement for real-world deployment. To overcome this, the recent popular network pruning is an effective method to reduce the redundancy of the models. However, the ranking of filters according to their ``importance'' on different pruning criteria may be inconsistent. One filter could be important according to a certain criterion, while it is unnecessary according to another one, which indicates that each criterion is only a partial view of the comprehensive ``importance''. From this motivation, we propose a novel framework to integrate the existing filter pruning criteria by exploring the criteria diversity. The proposed framework contains two stages: Criteria Clustering and Filters Importance Calibration. First, we condense the pruning criteria via layerwise clustering based on the rank of ``importance'' score. Second, within each cluster, we propose a calibration factor to adjust their significance for each selected blending candidates and search for the optimal blending criterion via Evolutionary Algorithm. Quantitative results on the CIFAR-100 and ImageNet benchmarks show that our framework outperforms the state-of-the-art baselines, regrading to the compact model performance after pruning.",
isbn="978-3-030-86380-7"
}

@Inbook{Ye2022,
author="Ye, Andre",
title="Model Compression for Practical Deployment",
bookTitle="Modern Deep Learning Design and Application Development: Versatile Tools to Solve Deep Learning Problems",
year="2022",
publisher="Apress",
address="Berkeley, CA",
pages="205--258",
abstract="Over the course of deep learning's flurried development in these recent decades, model compression has relatively recently become of prominent importance. Make no mistake -- model compression methods have existed and have been documented for decades, but the focus for much of deep learning's recent evolution was on expanding and increasing the size of deep learning models to increase their predictive power. Many modern convolutional networks today contain hundreds of millions of parameters, and Natural Language Processing models have reached hundreds of billions of parameters (and counting).",
isbn="978-1-4842-7413-2",
doi="10.1007/978-1-4842-7413-2_4",
url="https://doi.org/10.1007/978-1-4842-7413-2_4"
}

@online{TFMO,
  author = {tensorflow.org},
  title = {Model optimization},
  year = 2021,
  url = {https://www.tensorflow.org/lite/performance/model_optimization},
  urldate = {2021-12-05}
}

@online{TFPrune,
  author = {tensorflow.org},
  title = {Trim insignificant weights},
  year = 2021,
  url = {https://www.tensorflow.org/model_optimization/guide/pruning},
  urldate = {2021-12-05}
}

@online{TFCluster,
  author = {tensorflow.org},
  title = {Weight clustering},
  year = 2021,
  url = {https://www.tensorflow.org/model_optimization/guide/clustering},
  urldate = {2021-12-05}
}

@online{ESP32,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {ESP32 Technical Reference Manual},
  year = 2021,
  url = {https://www.espressif.com/sites/default/files/documentation/esp32_technical_reference_manual_en.pdf},
  urldate = {2021-12-05}
}

@online{ESPCompare,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {Chip Series Comparison},
  year = 2021,
  url = {https://docs.espressif.com/projects/esp-idf/en/latest/esp32/hw-reference/chip-series-comparison.html},
  urldate = {2021-12-06}
}

@Inbook{Cameron2021,
author="Cameron, Neil",
title="ESP32 microcontroller features",
bookTitle="Electronics Projects with the ESP8266 and ESP32: Building Web Pages, Applications, and WiFi Enabled Devices",
year="2021",
publisher="Apress",
address="Berkeley, CA",
pages="641--682",
abstract="Features specific to the ESP32 microcontroller are described in this chapter. In Chapter 21(Microcontrollers), differences in instructions for ESP8266 and ESP32 microcontrollers regarding features that are available to both microcontrollers were described. The ESP32 microcontroller has two cores, which are managed independently, Bluetooth communication and Bluetooth Low Energy (BLE) communication, four independent timers, a digital to analog converter (DAC) with capacitive touch sensors, and a Hall effect sensor. The ESP32 DEVKIT DOIT development board is illustrated in Figure 22-1.",
isbn="978-1-4842-6336-5",
doi="10.1007/978-1-4842-6336-5_22",
url="https://doi.org/10.1007/978-1-4842-6336-5_22"
}

@online{ESPFloat,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {ESP-IDF FreeRTOS SMP Changes},
  year = 2020,
  url = {https://docs.espressif.com/projects/esp-idf/en/v4.2/esp32/api-guides/freertos-smp.html},
  urldate = {2021-12-06}
}

@online{ESP32-S2,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {ESP32-S2 Technical Reference Manual},
  year = 2021,
  url = {https://www.espressif.com/sites/default/files/documentation/esp32-s2_technical_reference_manual_en.pdf},
  urldate = {2021-12-06}
}

@online{ESP32-C3,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {ESP32-C3 Technical Reference Manual},
  year = 2021,
  url = {https://www.espressif.com/sites/default/files/documentation/esp32-c3_technical_reference_manual_en.pdf},
  urldate = {2021-12-06}
}

@online{ESP32-S3,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {ESP32-S3 Technical Reference Manual},
  year = 2021,
  url = {https://www.espressif.com/sites/default/files/documentation/esp32-s3_technical_reference_manual_en.pdf},
  urldate = {2021-12-06}
}

@book{Oner2021,
  title={Developing IoT Projects with ESP32},
  author={Vedat Ozan Oner},
  isbn={9781838641160},
  url={https://books.google.de/books?id=sB3mxQEACAAJ},
  year={2021},
  publisher={Packt}
}

@online{ESPIDF,
  author = {Espressif Systems (Shanghai) Co., Ltd},
  title = {ESP-IDF},
  year = 2021,
  url = {https://www.espressif.com/en/products/sdks/esp-idf},
  urldate = {2021-12-06}
}

@Inbook{Süße2014,
author="S{\"u}{\ss}e, Herbert
and Rodner, Erik",
title="Maschinelles Lernen",
bookTitle="Bildverarbeitung und Objekterkennung: Computer Vision in Industrie und Medizin",
year="2014",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="449--513",
abstract="Im folgenden Kapitel werden wir einen {\"U}berblick {\"u}ber Verfahren des maschinellen Lernens bieten. Dabei werden wir uns auf etablierte Methoden konzentrieren, welche vor allem im Bereich der Bildverarbeitung Anwendung finden. Die F{\"a}higkeit eine Art der automatischen Bildanalyse und -erkennung von Objekten durchzuf{\"u}hren, ist sowohl in der Robotik als auch bei zahlreichen Anwendungen zwingend notwendig. In den letzten Jahren l{\"a}sst sich ein drastischer Anstieg an komplexen industriellen Problemstellungen verzeichnen, welche ohne Verfahren des maschinellen Lernens nicht realisierbar sind. Als pr{\"a}gnantes Beispiel sei hier die Fu{\ss}g{\"a}ngerdetektion  und zahlreiche andere Fahrerassistenzsysteme aufgef{\"u}hrt. Weiterhin st{\"o}{\ss}t die manuelle Optimierung von Parametern eines Algorithmus f{\"u}r eine gegebene Aufgabenstellung schnell an ihre Grenzen und die meisten Algorithmen der Bildverarbeitung besitzen Kontrollparameter welchen einen entscheidenden Einfluss auf die Ergebnisse haben. Methoden des maschinellen Lernens erm{\"o}glichen es einen Teil dieser Parameter automatisch aus gegebenen Daten zu lernen.",
isbn="978-3-8348-2606-0",
doi="10.1007/978-3-8348-2606-0_18",
url="https://doi.org/10.1007/978-3-8348-2606-0_18"
}

@book{Fach2018,
  title={Fachkunde Elektrotechnik},
  author={Werner Klee  Klaus Tkotz  Olaf Reichmann  Monika Burgmaier  Horst Bumiller  Bernd Feustel  Walter Eichler  Christian Duhr  Ulrich Winter  Jürgen Manderla  Thomas Käppel},
  isbn={978-3-8085-3479-3},
  year={2018},
  publisher={Europa Lehrmittel}
}

@Inbook{Meinecke2017,
author="Meinecke, Christopher",
title="Aufbau eines intelligenten Stromnetzes und Einf{\"u}hrung von Smart Metern in Deutschland",
bookTitle="Potentiale und Grenzen von Smart Metering : Empirische Wirkungsanalyse eines Feldtests mit privaten Haushalten",
year="2017",
publisher="Springer Fachmedien Wiesbaden",
address="Wiesbaden",
pages="13--72",
abstract="Wie in der Einf{\"u}hrung bereits skizziert, liegt die Ursache des grundlegenden Ver{\"a}nderungsprozesses der Elektrizit{\"a}tsversorgung in der Bundesrepublik in der klimawandelbedingten Legitimationskrise der Kohlekraft und dem Ausstieg aus der Atomenergie. Parallel zu dieser Entwicklung durchlaufen die europ{\"a}ische und die deutsche Elektrizit{\"a}tsversorgung seit einigen Jahren allerdings zus{\"a}tzlich einen Liberalisierungsprozess, der ebenfalls einen signifikanten Einfluss auf die Umstrukturierung der deutschen Elektrizit{\"a}tsversorgung hat.",
isbn="978-3-658-16064-7",
doi="10.1007/978-3-658-16064-7_2",
url="https://doi.org/10.1007/978-3-658-16064-7_2"
}



@Comment{
@misc{MBG,
    title        = {Gesetz über den Messstellenbetrieb und die Datenkommunikation in intelligenten Energienetzen},
    author       = {Deutschland},
    year         = {2016},
    url          = {http://www.gesetze-im-internet.de/messbg/BJNR203410016.html},
    urldate      = {2021-12-09}
}
}

@Comment{jabref-meta: databaseType:bibtex;}
