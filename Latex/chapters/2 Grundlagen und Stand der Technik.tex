\chapter{Grundlagen und Stand der Technik}\label{ch:TGrundlagen und Stand der Technik}
    In diesem Kapitel werden zunächst alle für die Arbeit wichtigen Grundlagen sowie der aktuelle Stand der Technik beschrieben. Auch der Stand der Technik innerhalb des SiGI Projekts wird dargelegt. Thematisch ist dieses Kapitel in \nameref{sec:Zaehlerwesen in Deutschland}, \nameref{sec:Machine Learning}, \nameref{sec:Machine Learning auf mobilen und eingebetteten Systemen}, \nameref{sec:ESP32-Baureihe} und \nameref{sec:Aktueller Stand im Projekt SiGI} unterteilt.

\section{Zählerwesen in Deutschland}\label{sec:Zaehlerwesen in Deutschland}
    Dieses Kapitel beschreibt die für das Projekt SiGI relevanten Grundlagen im Bereich des Zählerwesens. Dabei wird zunächst die Entwicklung des Zählerwesens in Deutschland bis hin zur aktuellen Situation beschrieben. Anschließend werden die Auswirkungen von aktuellen Veränderungen der Regularien des Zählerwesens auf digitale Geschäftsmodelle beleuchtet.

\subsection{Entwicklung des Zählerwesens}\label{subsec:Entwicklung}
    Die Entwicklung des Zählerwesens beginnt mit den analogen Zählern. Analoge Zähler setzen die Messgröße meist mechanisch in eine Bewegung der Anzeigeinstrumente um. Dabei wird das Zählwerk, dargestellt in Abbildung~\ref{fig:2.1}, welches aus mit Ziffern bedruckten Rädern besteht, entsprechend dem Verbrauch gedreht.\fig{2.1}{Zählwerk eines analogen Stromzählers (Eigendarstellung)} Der absolute Zählerstand kann an der Anzeige abgelesen werden. Zusätzlich verfügen einige analoge Zähler über Impulsausgänge. Diese Ausgänge liefern immer dann einen Impuls, wenn eine bestimmte Menge verbraucht wurde. Diese Impulsausgänge müssen nicht zwangsläufig elektrisch ausgeführt sein, bei vielen Modellen muss der Impuls durch ein separates Gerät erst erfasst werden. Gängig sind zum Beispiel optische Maker an Drehscheiben oder aber magnetische Aufsätze für Drehscheiben. Durch die sensorische Erfassung dieser können die Verbrauchsdaten inkrementell erfasst werden\cite{Fach2018}.\\ In den Sparten Gas und Wasser sind analoge Zähler immer noch weit verbreitet. Lediglich sehr große Gasverbraucher sind verpflichtet, Lastgangmessungen mit elektronischen bzw. digitalen Zählern durchzuführen. Anders sieht es in der Sparte Strom aus. Hier ist der Einbau von elektronischen Haushaltszählern seit 2008 für Neubauten gesetzlich vorgeschrieben. Hintergrund dieses verpflichtenden Einbaus ist die Bereitstellung von detaillierten Messdaten. So speichert der elektronische Haushaltszähler verschiedenen Verbrauchsdaten über einen längeren Zeitraum hinweg. Es können zum Beispiel auch Tages- und Monatsverbräuche abgerufen werden. Darüber hinaus bietet der elektronische Zähler die Möglichkeit, die Verbrauchsdaten mit einer digitalen Schnittstelle fernauslesbar zu machen\cite{Meinecke2017}.\\ Im Jahr 2016 wurden die Anforderungen an die Zähler in der Sparte Strom noch einmal verschärft. Mit Inkrafttreten des Messstellenbetriebsgesetzes werden der Datenschutz und die informationstechnische Sicherheit der Zähler bzw. der Zählerfernablesung in den Vordergrund gerückt. So müssen Messstellen mit einer modernen Messeinrichtung ausgestattet werden, wenn dies wirtschaftlich vertretbar ist. Eine moderne Messeinrichtung ist ein digitaler Zähler, welcher einer Reihe von gesetzlichen Anforderungen an Datenschutz bzw. -sicherheit erfüllt. Außerdem besteht die Möglichkeit, eine moderne Messeinrichtung durch die Anbindung an ein Smart Meter Gateway zu einem intelligenten Messsystem aufzurüsten. Dieses ist durch das Smart Meter Gateway fernauslesbar (vgl. Messstellenbetriebsgesetz).

\subsection{Auswirkungen auf digitale Geschäftsmodelle}\label{subsec:Smart Meter Rollout}
    Wie im Kapitel~\nameref{subsec:Entwicklung} beschrieben, ist die Digitalisierung des Zählerwesens in den verschiedenen Sparten unterschiedlich weit fortgeschritten. Während es im Bereich von Gas- und Wasserzählern kaum digitale Verbrauchsdaten oder gesetzliche Vorgaben zur Digitalisierung der Messsysteme gibt, ist die Verfügbarkeit von Verbrauchsdaten im Bereich Strom heute schon verhältnismäßig hoch und wird durch das gesetzliche Ausrollen der intelligenten Messsysteme weiter steigen (vgl. Messstellenbetriebsgesetz).\\ Die flächendeckende und spartenübergreifende Verfügbarkeit von Verbrauchsdaten ist allerdings die Grundlage für eine Reihe digitaler Geschäftsmodelle in diesem Bereich. So können aus den kombinierten Verbrauchsdaten von Wasser und Strom zum Beispiel besser Informationen über den Verbrauch von Waschmaschinen gesammelt werden. Das kann zum Beispiel bei der Suche nach Fehlern in defekten Geräten hilfreich sein. In vielerlei Hinsicht lassen sich die Verbrauchsdaten der Sparten erst gemeinsam als Basis für viele digitale Geschäftsmodelle nutzen. Eine mögliche Anwendung wäre zum Beispiel die Erkennung der Anwesenheit von Personen in einem Haushalt. So könnte zum Beispiel alten Leuten, die gestürzt sind, geholfen werden, in dem erkannt wird, wann sie von ihrem typischen Verbrauchsverhalten abweichen. Die Ablesung von Zählerständen könnte durch eine flächendeckende Anbindung von Zählern komplett wegfallen.\\ Die Entwicklung des SiGI Projektes erfolgt vor dem Hintergrund der fehlenden Möglichkeit, Gas- und Wasserzähler an einen Fernablesung anzubinden. Wie bereits beschrieben, sind in diesen Sparten die analogen Zähler immer noch die deutlich größte Gruppe von Zählern. Theoretisch wäre es zwar denkbar, die Impulsausgänge der analogen Zähler digital zu erfassen und weiterzuleiten, allerdings bilden diese nicht das gesamte Spektrum von Verbrauchsdaten ab, welche ein digitaler Zähler bereitstellt. Das größte Problem ist die fehlende Möglichkeit einer Absolutwerterfassung. Der Impulsausgang liefert immer nur eine Information darüber, in welcher Zeit eine diskrete Energiemenge verbraucht wird. Diese Lösung ist dadurch zum einen auf eine initiale Ablesung des Zählerstandes angewiesen, zum anderen sehr anfällig für Übertragungsfehler. Werden einer oder mehrere Impulse nicht gezählt, da zum Beispiel die Weiterleitung der Daten per Funk nicht funktioniert, wird die Energiemenge nicht gezählt. Auch falls der Fehler nur temporär ist bzw. behoben werden kann, muss der Zählerstand im Anschluss manuell erfasst werden. Darüber hinaus sind kurze Fehlerzustände schwer zu detektieren, da sich ein fehlender Impuls nur in einem geringeren Energieverbrauch äußert.\\ Aus diesem Grund hat das Projekt SiGI das Ziel, eine Absolutwerterfassung zu gewährleisten. So können die sich im Betrieb befindlichen analogen Zähler weiter betrieben und dennoch digital angebunden werden und somit wertvolle Daten für verschiedene digitale Geschäftsmodelle liefern. 

\section{Maschinelles Lernen}\label{sec:Machine Learning}
    Dieses Kapitel gibt einen grundlegenden Überblick über die relevanten Techniken und Verfahren im Bereich des maschinellen Lernens. Dazu wird zunächst erläutert, was unter maschinellem Lernen zu verstehen ist und wie sich die unterschiedlichen Verfahren unterteilen lassen. Anschließend werden der Aufbau sowie die Anwendungsmöglichkeiten von Neuronalen Netzen behandelt. Ein besonderer Fokus wird dabei auf die für diese Arbeit wichtige Detektion von Ziffern in Bildern gelegt.
\subsection{Was ist maschinelles Lernen?}\label{subsec:Was ist maschninelles Lernen?}
    Unter maschinellem Lernen werden eine Reihe unterschiedlicher Algorithmen und Verfahren zusammengefasst. Die Aufgaben solcher Verfahren können in der Praxis stark variieren. Basis für die Algorithmen im Feld des maschinenellen Lernens ist dabei immer die Annäherung einer mathematischen Funktion anhand von Daten. Diese dient dazu, Muster innerhalb eines Datensatzes zu erkennen und zu generalisieren\cite{Goodfellow-et-al-2016-5}.\\ Das Grundkonzept maschinellen Lernens wird zunächst anhand eines einfachen Verfahrens dargestellt. Soll eine grobe Abschätzung eines Zusammenhangs zweier Parameter, zum Beispiel die Abhängigkeit der Kosten eines Mikrocontrollers $y$ von der gewünschten Arbeitsspeichergröße $x$, vorgenommen werden, kann ein lineares Modell (Gleichung~\ref{eq:2.1}) zugrunde gelegt werden, da ein proportionaler Zusammenhang angenommen werden kann. 
    \begin{equation}
        y\ = m\ *\ x\ +\ b
    \end{equation}\label{eq:2.1}
    Um die Funktion zu bestimmen, welche die Abhängigkeit der Kosten vom Arbeitsspeicher annähert, wird eine sogenannte lineare Regression durchgeführt. Die Steigung $m$ und der y-Achsenabschnitt $b$ werden mit diesem Verfahren so bestimmt, dass die Funktion möglichst genau den tatsächlichen Zusammenhang abbildet. Um die optimalen Parameter zu bestimmen, benötigt man möglichst viel Daten beispielhafter Mikrocontroller. Zu Beginn sind die beiden Parameter $m$ und $b$ zufällig gewählt. Wird das Modell genutzt, um die Kosten eines der Mikrocontrollers zu bestimmen, ergibt sich meist eine relativ große Abweichung vom tatsächlichen Preis. Ziel der linearen Regression ist es, diese für alle Mikrocontroller des Datensatzes möglichst klein zu halten\cite{Kossen2019}.\\ Um bei der Optimierung unabhängig vom Vorzeichen der Abweichung vorgehen zu können wird als Fehlerfunktion meist der mittlere quadratische Fehler verwendet. Dabei werden alle Abweichungen zunächst quadriert, dann aufsummiert und durch die Anzahl von Abweichungen bzw. Daten geteilt\cite{James2013-2}. Der so berechnete Fehler muss dann im Rahmen des Lernprozesses minimiert werden. Eine gängige Methode zur Minimierung von Fehlern ist der Gradienten-Abstieg. Dabei wird die Fehlerfunktion partiell nach den beiden Parametern $m$ und $b$ abgeleitet. Werden die Ableitungen der jeweiligen Parameter von den Parametern selbst subtrahiert, ergibt sich in jedem Fall eine Minimierung des Fehlers. Ist zum Beispiel der y-Achsenabschnitt $b$, also die minimalen Fixkosten die bei einem Mikrocontroller immer anfallen, zu groß gewählt, müsste, wenn der Parameter $b$ sich weiter erhöht, der Fehler weiter steigen. Die Ableitung ist also so lange positiv, wie die Fixkosten zu hoch geschätzt sind. Sinken diese unter den Optimalwert, ändert sich das Vorzeichen der Ableitung. Der Parameter verbleibt in einem Bereich, in dem der Fehler ein lokales Minimum hat\cite{Böttcher2019-22}\cite{GradientDescent}.\\ Auf die Fehlerfunktion sowie den gradienten Abstieg wird im Kapitel~\nameref{subsec:Neuronale Netze} weiter eingegangen. Diese einfachen Konzepte lassen sich leicht modifiziert auch auf komplexere Modelle und Verfahren übertragen. 

\subsection{Supervised Learning und Unsupervised Learning}\label{subsec:Supervised Learning und Unsupervised Learning}
    Um einen Überblick über die im Bereich des maschinellen Lernens gängigen Verfahren zu erlangen, ist es sinnvoll, diese anhand bestimmter Eigenschaften zu unterteilen. Ein gängiges Unterscheidungsmerkmal ist die Struktur der zum Training verwendeten Daten.\\
    Wird zum Beispiel die im Kapitel~\nameref{subsec:Was ist maschninelles Lernen?} beschriebene lineare Regression betrachtet, ist zu erkennen, dass für jeden Mikrocontroller im Datensatz die Kosten bekannt sein müssen. Ein solcher Datensatz wird als gelabelt bezeichnet. Ein Datum besteht also jeweils aus einem Merkmalsvektor, den Anforderungen an den Mikrocontroller, und einem Label, den bekannten Kosten des Mikrocontrollers. Setzen Verfahren gelabelte Daten voraus, spricht man von überwachtem Lernen bzw. Supervised Learning\cite{Richter2019_1}.\\ Auch wenn ein Datensatz keine Label beinhaltet, lassen sich Informationen aus diesem gewinnen. Sind die Kosten eines Mikrocontrollers zum Beispiel unbekannt, lassen sich die einzelnen Ausführungen anhand ihres Arbeitsspeichers immer noch in Gruppen einteilen. So können Mikrocontroller, welche von unterschiedliche Herstellern für ähnliche Anwendungen entwickelt wurden, sehr ähnliche technische Eigenschaften haben. Wird der Arbeitsspeicher unterschiedlicher Mikrocontroller auf einer Geraden aufgetragen, kann also anhand des Abstandes und der Häufung ein Muster erlernt werden. Ein solches Verfahren, bei dem keine Label benötigt werden, wird als unüberwachtes Lernen bzw. Unsupervised Learning bezeichnet. In der Praxis ist das Lernen eindimensionaler Muster wenig sinnvoll. Häufig hat der Merkmalsvektor mehr als nur einen Eintrag, also beispielsweise zusätzliche Informationen zur Rechenleistung und CPU-Taktung des Mikrocontrollers\cite{Richter2019_9}.\\ Im Projekt SiGI wird ein Verfahren aus dem Bereich des Supervised Learnings verwendet, da eine konkrete Vorhersage über die Position einer Ziffer in einem Bild benötigt wird. Unsupervised Learning Verfahren sind für diesen Aufgabentyp nicht geeignet, da sie nicht nach zuvor definierten Informationen suchen\cite{James2013-12}.  
    
\subsection{Anwendungsarten maschinellen Lernens}\label{subsec:Unterschiedliche Machine Learning Verfahren}
    Verfahren des maschinellen Lernens lassen sich nicht nur Anhand der Struktur ihrer Daten, sondern auch anhand der Probleme, die sie lösen, unterteilen. So löst die lineare Regression ein Regressionsproblem. Die angenäherte Funktion bildet den Merkmalsvektor auf einen reellen, numerischen Parameter, die Kosten, ab. Die angenähert Funktion wird im Nachgang dazu verwendet, den Parameter für unbekannte Merkmalsvektoren vorherzusagen\cite{Goodfellow-et-al-2016-5}.\\ Maschinelle Lernverfahren können allerdings nicht nur zur Vorhersage einzelner numerischer Parameter genutzt werden. Auch Klassifizierungsprobleme können auf ähnliche weise gelöst werden. Sollen beispielsweise Bilder (Merkmalsvektoren) von Ziffern der entsprechenden Ziffer zugeordnet werden, ist die Ausgabe eines reellen Parameters nicht sinnvoll, da es beispielsweise keine Ziffer $9,5$ gibt. Stattdessen wird eine Funktion angenähert, welche den Merkmalsvektor auf, in diesem Fall, zehn Parameter abbildet. Diese stellen die Wahrscheinlichkeit dar, dass es sich bei dem Bild um die jeweils dem Parameter zugeordnete Ziffer handelt\cite{Goodfellow-et-al-2016-5}. Alternativ lässt sich auch eine Funktion annähern, welche die Daten in einem Merkmalsraum in unterschiedliche Klassen unterteilt. Dabei verwendet man die einzelnen Merkmale als Basisvektoren des Merkmalsraums\cite{Ertel2016}. Der einfachste Fall ist dabei ein eindimensionaler Merkmalsraum. Es kann also die Funktion angenähert werden, welche den maximalen Arbeitsspeicher eines Mikrocontrollers ausgibt. Somit würde die Funktion die Grenze zwischen Mikrocontroller und nicht Mikrocontroller darstellen. Praktisch ist eine solche eindimensionale Betrachtung nicht sinnvoll. In der Praxis hängt die Entscheidung, ob ein Gerät ein Mikrocontroller ist, von vielen Merkmalen ab. Die Klassifizierung kann also nur in einem höherdimensionalen Merkmalsraum erfolgen.\\ Eine etwas speziellere Kategorie von Verfahren sind die Objekterkennungs- bzw. Objektlokalisationsverfahren. Mit Hilfe von Objekterkennungsverfahren lassen sich einzelne Objekte auf Bildern nicht nur klassifizieren sondern auch lokalisieren. Der Merkmalsvektor ist, wie bei der Klassifizierung, das Bild. Die Ausgabe enthält Positionsdaten, Größen und Klassifizierungen aller im Bild detektierten Objekte\cite{Süße2014}. Da Objekterkennungsverfahren und Objekterkennung für diese Arbeit besonders relevant sind, wird diesem Thema ein eigenes Kapitel gewidmet. Die Erläuterung der Funktion von Objekterkennung wird nach dem Kapitel~\nameref{subsec:Neuronale Netze} im Kapitel~\nameref{subsec:Anwendungen in der Bildverarbeitung} vorgenommen.

\subsection{Neuronale Netze}\label{subsec:Neuronale Netze}
    Neuronale Netze können mathematisch als universelle Regressoren aufgefasst werden\cite{Livshin2022}. Das bedeutet, dass mit ihnen Funktionen jeglicher Art angenähert werden können. Damit können sie grundsätzlich sowohl für Regressions- als auch für Klassifikationsprobleme eingesetzt werden. Auch Objekterkennung ist in der Praxis ohne Neuronale Netze kaum noch verbreitet. Neuronale Netze haben klassische Bildverarbeitungsverfahren abgelöst\cite{Pang2019-2}.\\ Neuronale Netze sind Strukturen, welche dem menschlichen Gehirn im weitesten Sinne nachempfunden sein sollen. Sie bestehen aus Schichten von Neuronen. Neuronen sind mit Neuronen anderer Schichten verbunden. Jeder Verbindung wird ein Parameter, das Gewicht, zugeordnet. Jedes Neuron hat eine Aktivierungsfunktion, welche bestimmt, wie die Aktivierung des Neurons berechnet wird. Diese Aktivierung wird an alle nachfolgenden Neuronen weitergegeben, mit dem dieses Neuron verbunden ist. In einem Neuron der nächsten Schicht werden dann alle eingehenden Aktivierungen vorheriger Neuronen mit den jeweiligen Gewichten der Verbindung beider multipliziert. Dann wird über alle Aktivierungen summiert. Die Summe ist der Wert, aus welchem mit der Aktivierungsfunktion die Aktivierung des Neurons berechnet wird\cite{Xia2019}.\\ Soll das Neuronale Netz nun eine Vorhersage oder eine Zuordnung eines Datum treffen, werden die Elemente des Merkalmsektors an die Neuronen der ersten Schicht übergeben. Das können zum Beispiel die Graustufenwerte jedes Pixels eines Bildes sein. Mit den Gewichten werden dann Schicht für Schicht die Aktivierungen aller Neuronen, bis zur letzten Schicht, berechnet. Die Aktivierungen der letzten Schicht sind die Ausgaben des Neuronalen Netzes. In diesem Beispiel können es zehn Aktivierungen sein, denen jeweils eine der Ziffern Null bis Neun zugeordnet ist. Das Graustufenbild zeigt demnach die Ziffer, bei der die Aktivierung maximal ist\cite{James2021-10}.\\ Noch sind die Ergebnisse, die das Neuronale Netz liefert, zufällig und die Bilder werden nicht korrekt klassifiziert. Was fehlt, ist der Trainingsprozess. Hierzu wird im einfachsten Fall, wie bei der linearen Regression, der Fehler als mittlere quadratische Abweichung der Aktivierungen der letzten Schicht von den Label berechnet. Liegt zum Beispiel ein Bild vor, von dem bekannt ist, dass darauf eine Fünf zu sehen ist, sollte das sechste Neuron eine maximale Aktivierung haben, während alle anderen Neuronen möglichst jeweils eine Aktivierung von null haben sollten. Um nun die Gewichte des Neuronalen Netzes anpassen zu können, wird wieder der Gradienten-Abstieg verwendet. Da das Modell in diesem Fall keine lineare Gleichung, sondern ein Neuronales Netz ist, beinhaltet es deutlich mehr trainierbare Parameter, nach denen abgeleitet werden muss. Wird ein Vektorraum mit den trainierbaren Parametern als Basisvektoren gebildet, ist der Gradient der Fehlerfunktion in diesem Vektorraum der Vektor, dessen Elemente die partiellen Ableitungen nach den Parametern sind. Der Ortsvektor enthält dabei die aktuellen Parameter des Neuronalen Netzes. Wird der Gradient der Fehlerfunktion von diesem Ortsvektor abgezogen, resultiert daraus, wie schon bei der linearen Regression, ein optimierter Satz an Parametern. Der resultierende Vektor enthält die neuen Parameter des Netzes. Dieser Prozess wird mit dem gesamten Trainingsdatensatz mehrfach wiederholt, um das Neuronale Netz zu trainieren\cite{Goodfellow-et-al-2016-6}.\\ In der Praxis können Neuronale Netz in ihrer Struktur variieren. So gibt es Netze, bei denen auch die Neuronen trainierbare Parameter haben oder auch Verbindungen nicht nur zwischen benachbarten Schichten existieren. Im Projekt SiGI wird ein Neuronales Netz mit Schichten, die auf der Faltungsoperation basieren, eingesetzt\cite{Pang2019-2}.

\subsection{Detektion von Ziffern in Bildern}\label{subsec:Anwendungen in der Bildverarbeitung}
    Sollen nun Ziffern nicht nur klassifiziert sondern auch lokalisiert werden, wird ein Objekterkennungs-Modell benötigt. Diese lassen sich entweder der Mulit-Shot Architektur oder der Single-Shot Architektur zuordnen. Bei Mulit-Shot Architekturen werden Lokalisation und Klassifikation voneinander getrennt. Durch einen Algorithmus werden zunächst Vorschläge für mögliche Objektpositionen erstellt. Diese werden dann durch ein Neuronales Netz klassifiziert. Bei Single-Shot Architekturen führt hingegen ein Neuronales Netz beide Schritte aus\cite{Pang2019-2}. Das Neuronale Netz gibt die wahrscheinlichsten Positionen für Objekte inklusive ihrer Klassifizierung aus.\\ Das im Projekt SiGI verwendete Modell ist den Single-Shot Architekturen zuzuordnen. Wie bereits erwähnt enthält das Modell Schichten, welche auf der Faltungsoperation basieren. Der Eingangswert der Aktivierungsfunktion bildet sich aus der Faltung mehrerer benachbarter Pixel. So erfassen Neuronen Bereiche des Bildes und können diesen Eigenschaften zuordnen. Die Neuronen dieser Schichten bilden das Bild zweidimensional ab. Es folgt eine zweite Schicht, welche die Eigenschaften lokal zusammenfasst. Mit jeder Schicht sinkt die Anzahl der Neuronen. Diese repräsentieren immer größere Bereiche des Bildes und ordnen diesen immer komplexere Eigenschaften zu. So können zum Beispiel in den ersten Schichten Kanten erkannt werden, in tiefer gelegenen Schichten dann beispielsweise schon Formen wie Ziffern. Die entstehenden Bildrepräsentationen werden als Feature Maps bezeichnet, da sie Merkmale des Bildes in zwei Dimensionen abbilden\cite{Xiao2021}.\\ Das SiGI Objekterkennungsmodell wurde mit der Tensorflow Object Detection API entwickelt, einer API mit der Neuronale Netze für den Einsatz in der Objekterkennung trainiert werden können. Diese verwendet standardmäßig Neuronale Netze, welche als Klassifikatoren entworfen wurden, um die Feature Map eines Bildes zu generieren. Konkret basiert der Objektdetektor auf der MobileNet Architektur. Diese ist um weitere Schichten erweitert, welche dazu dienen, aus den Merkmalen abzuleiten, wo sich die gesuchten Objekte, also die Ziffern, befinden. Diese Schichten arbeiten dabei mit unterschiedlichen Größen von Regionen, in denen nach Objekten gesucht wird. Die Regionen, in denen Objekte mit der höchsten Wahrscheinlichkeit detektiert werden, werden als Ergebnisse ausgegeben\cite{Chen2021}.\\ Der Teil des Netzes, welcher die Merkmale des Bildes generiert, wird bei der Verwendung der Tensorflow Object Detection API vor dem eigentlichen Trainingsprozess bereits unabhängig von der konkreten Objektart trainiert. Dieser Prozess ist enorm aufwändig und benötigt große Mengen an gelabelten Daten. Da es nicht wirtschaftlich ist, dies für jeden Anwendungsfall separat zu tun, werden bereits vortrainierte Netze durch die API zur Verfügung gestellt\cite{TFODAPI}. Das SiGI Modell basiert auf einem solchen vortrainierten Modell, das mit einem Datensatz von Bildern von analogen Zählern nachtrainiert ist. Eine beispielhafte Darstellung der Ausgabe des Neuronalen Netzes ist in Abbildung~\ref{fig:2.2} dargestellt.\fig{2.2}{Ausgabe des Modells (Quelle: EWE AG)}
    
\section{Maschinelles Lernen auf mobilen und eingebetteten Systemen}\label{sec:Machine Learning auf mobilen und eingebetteten Systemen}
    Um ein Neuronales Netz auf mobilen und eingebetteten Systemen betreiben zu können, müssen die Ausführung sowie die Architektur des Modells auf die begrenzten Ressourcen dieser Geräte angepasst werden. Dieses Kapitel behandelt Besonderheiten und Probleme sowie Optimierungsverfahren für den Einsatz von Neuronalen Netzen auf begrenzter Hardware. Dabei wird ein Fokus auf Lösungen im Rahmen des Tensorflow Lite Frameworks gelegt. Das Tensorflow Lite Framework ist ein Framework, mit dem Neuronale Netze speziell für den Einsatz auf mobilen und eingebetteten Systemen optimiert werden können.
\subsection{Besonderheiten und Probleme}\label{subsec:Besonderheiten und Probleme}
    Zwischen konventionellen Desktop Computern bzw. Servern und mobilen und eingebetteten Systemen gibt es einige fundamentale Unterschiede. So sind mobile und eingebettete Systeme sowohl in Bezug auf ihre Größe, aber auch in Bezug auf ihren Energieverbrauch stark optimiert. Besonders deutlich wird dies bei Mikrocontrollern. Hier ist die Optimierung des Energieverbrauchs am größten. In der Folge sind beim Einsatz von maschinellen Lernverfahren auf entsprechender Hardware die veränderte Architektur und die begrenzten Ressourcen zu beachten\cite{warden2020tinyml}.\\ Zunächst ist festzustellen, dass nicht alle eingebetteten Systeme auf einer Von-Neumann-Architektur basieren. Auch die Harvard-Architektur bzw. Modifikationen dieser kommen gerade im Bereich von Mikrocontrollern zum Einsatz. Zusätzlich können die Adressräume und die Registerbreite solcher Systeme kleiner als bei Desktop Rechnern ausfallen\cite{Currie2021}.\\ Um den Anforderungen an eine geringe Größe und vor allem an einen geringen Energieverbrauch gerecht zu werden, ist die Rechenleistung von mobilen und eingebetteten Systemen sehr begrenzt. Es ist in der Regel nicht möglich bzw. nicht in angemessener Zeit möglich, ein Modell auf einem solchen Gerät zu trainieren. Deshalb ist das gängige Vorgehen, die Modelle auf leistungsfähigeren Rechnern zu trainieren und diese dann auf dem mobilen oder eingebetteten System auszuführen. Je nach Komplexität des Modells kann auch diese Ausführung viel Zeit in Anspruch nehmen. Für viele einfache Anwendungen ist die Laufzeit allerdings ausreichend\cite{TFLITE}.\\ Ein weiterer Faktor, welcher den Einsatz von maschinellen Lernverfahren auf Mikrocontrollern einschränkt, ist die begrenzte Verfügbarkeit von Arbeitsspeicher. Dabei ist nicht nur die Größe an sich, sondern auch die Art des Zugriffs auf den Arbeitsspeicher relevant. Damit der Arbeitsspeicher für ein mit Tensorflow Lite for Microcontrollers erstelltes Neuronales Netz nutzbar ist, muss dieser kontinuierlich und linear adressiert sein. Ist also der Adressraum des Systems zu klein, limitiert dessen Größe den Einsatz von Neuronalen Netzen\cite{warden2020tinyml}.\\ Um das Modell nicht nur speichern sondern auch ausführen zu können, müssen auch die benötigten mathematischen Operationen von der Hardware unterstützt sein. So muss sichergestellt sein, dass ein Modell, welches auf Hardware mit nicht bzw. nur eingeschränkt unterstützter Gleitkommaarithmetik ausgeführt werden soll, keine Gleitkommazahlen enthält bzw. voraussetzt\cite{warden2020tinyml}.

\subsection{Laufzeit- und Speicheroptimierungsverfahren}\label{subsec:Laufzeit- und Speicheroptimierungsverfahren}
    Da nicht alle Hardwareanforderungen immer so umgesetzt werden können bzw. weil die Umsetzung zu kostenintensiv wäre, gibt es Möglichkeiten, Modelle auf die spezifische Hardware anzupassen. So gibt es für die unterschiedlichen unterstützten Baureihen hardwarespezifische Interpreter. Diese führen die im Arbeitsspeicher abgelegten Modelle aus. Dabei werden die Interpreter für die jeweilige Baureihe bzw. das jeweilige Modell kompiliert. Dadurch können die spezifischen Eigenschaften der Hardware optimal ausgenutzt werden\cite{warden2020tinyml}.\\ Auch das Modell an sich kann für die Ausführung auf Hardware mit begrenzten Ressourcen optimiert werden. Ein Verfahren ist die Quantisierung des Modells. Dabei werden anstatt der üblichen 32-Bit Gleitkommazahlen 16-Bit Gleitkommazahlen oder 8-Bit Ganzzahlen für die Gewichte und die Aktivierungen verwendet. So kann der für die Gewichte benötigte Arbeitsspeicher bis um den Faktor Vier reduziert werden. Auch die Ausführungszeit kann dadurch reduziert werden, da die Arithmetik mit kleinerer Präzision schneller durchgeführt werden kann. Besonders stark ist dieser Effekt bei einer Ganzzahl-Quantisierung. Durch die Quantisierung sinkt allerdings die Genauigkeit des Modells. Um diesen Effekt zu minimieren, gibt es Ansätze, die Modelle entweder bereits mit den quantisierten Typen zu trainieren oder nach der Quantisierung die Gewichte nachzujustieren\cite{Quant}.\\ Neben der Reduktion des benötigten Arbeitsspeichers je Gewicht kann auch die Anzahl der benötigten Gewichte eines Modells reduziert werden. Eine Möglichkeit, dies zu erreichen, ist das sogenannte Beschneiden eines Neuronalen Netzes. Dabei werden Gewichte und die zugehörigen Pfade durch das Neuronal Netz ignoriert, wenn ihr Einfluss auf die Ergebnisse zu gering ist. Dabei ist zu beachten, dass der Fehler des Neuronalen Netzes im allgemeinen mit jeder Beschneidung steigt. Es muss also zwischen Genauigkeit und Größe bzw. Laufzeit eines Modells abgewogen werden. Wie auch bei der Quantisierung gibt es die Möglichkeit, nach einer Beschneidung das Netz noch einmal mit einem Teil der Daten zu trainieren, um die Auswirkungen auf den Fehler gering zu halten\cite{Prune}.\\ Eine weitere Möglichkeit, die Anzahl der zu speichernden Gewichte zu reduzieren, ist die Gruppierung dieser. Dabei werden ähnliche Gewichte leicht angepasst, sodass sie den gleichen Wert haben. Mehrere Verbindungen können sich so den Speicherplatz teilen. Es ist zu beachten, dass durch diese Verfahren in der Regel nur die benötigte Speicherkapazität, nicht aber die Laufzeit reduziert wird. So haben zwar mehrere Gewichte den gleichen Wert, müssen aber mit unterschiedlichen Aktivierungen multipliziert werden. Es reduziert sich also nicht, wie beim Beschneiden die Anzahl der notwendigen Operationen\cite{Ye2022}.  

\subsection{Optimierungsverfahren und Tensorflow Object Detection API}
    Aus der Verwendung der Tensorflow Object Detection API ergeben sich einige Einschränkungen was die Möglichkeiten der Anwendung von Optimierungsvervahren betrifft. So ist nur die Verwendung des Tensorflow Lite Frameworks als Framework für die Ausführung auf mobilen Systemen möglich. Für die Ausführung von Neuronalen Netzen auf Mikrocontrollern muss Tensorflow Lite for Microcontrollers verwendet werden. Tensorflow Lite for Microcontrollers ist eine Erweiterung des Tensorflow Lite Framworks, speziell für die Ausführung von Neuronalen Netzen auf Mikrocontrollern. Die Frameworks unterstützen die in Kapitel~\nameref{subsec:Laufzeit- und Speicheroptimierungsverfahren} beschriebene Generierung von hardwarespezifischen Interpretern. Auch die Optimierung von Modellen mit den bereits beschriebenen Verfahren wird grundsätzlich aus dem Framework heraus unterstützt. Allerdings sind die Optimierungsverfahren aktuell nur für bestimmte Typen von Modellen bzw. Modellkomponenten implementiert\cite{TFMO}.\\ Die Quantisierung ist als Standardverfahren der Modelloptimierung für alle möglichen Architekturen innerhalb des Tensorflow Frameworks implementiert. Auch bei den durch die Tensorflow Object Detection API verwendeten Modelle können problemlos quantisiert werden. Dazu wird beim Konvertieren des Modells in ein für mobile und eingebettete Systeme nutzbares Format der Zieltyp bzw. die Art der Quantisierung angegeben. Allein mit dieser Methode können die verwendeten Modelle auf etwa ein Viertel ihrer ursprünglichen Größe reduziert werden. Auch eine hardwareabhängige Reduktion der Laufzeit ist zu erwarten\cite{TFMO}.\\ Anders als bei der Quantisierung sind die Gruppierung von Gewichten und Beschneidung eines Neuronalen Netzes aktuell nur für einige Modelle innerhalb des Tensorflow Frameworks implementiert. Diese Verfahren können während des Konvertierungsprozesses auf Neuronale Netze oder Schichten von Neuronalen Netzen angewendet werden, welche mit Hilfe der Keras Bibliothek entwickelt wurden. Keras ist eine Bibliothek, mit der Neuronale Netze erstellt werden können. Da die vortrainierten Modelle der Tensorflow Object Detection API aktuell nicht auf Keras basieren, ist eine Anwendung dieser Verfahren nicht ohne Weiteres möglich\cite{TFPrune}\cite{TFCluster}.  

\section{ESP32-Baureihe}\label{sec:ESP32-Baureihe}
    Im Rahmen dieser Arbeit wird die praktische Erprobung der entwickelten Konzepte auf der ESP32 Baureihe durchgeführt. Dieses Kapitel fasst alle für den Betrieb von Neuronalen Netzen wichtigen Informationen zusammen. Zunächst wird auf die Besonderheiten der Architektur der Baureihe eingegangen. Anschließend werden der Aufbau des Arbeitsspeichers und wirtschaftliche Faktoren näher betrachtet.

\subsection{Architektur des Mikrocontrollers}
    Bei der ESP32 Baureihe handelt es sich um Mikrocontroller mit einer 32-Bit Architektur. Es sind sowohl Modelle mit einem als auch mit zwei Prozessorkernen verfügbar. Die Rechnerarchitektur entspricht einer modifizierten Harvard-Architektur. Auf den genauen Aufbau des Arbeitsspeichers und dessen Anbindung über den Bus wird im Kapitel~\nameref{subsec:Aufbau des Arbeitsspeichers} eingegangen. Die ESP32-Baureihe wurde ursprünglich für den Einsatz in IoT-Geräte entwickelt. So sind die Modelle der Baureihe mit einer Reihe von unterschiedlichen Peripherieeinheiten ausgestattet. Zunächst ist die Wifi-Schnittstelle zu erwähnen. Darüber hinaus sind Schnittstellen für viele der gängigen Bussysteme, wie SPI, I2C und UART ausgeführt. Die meisten Modelle verfügen zusätzlich auch über eine Bluetooth-Schnittstelle sowie Analog-Digital- bzw. Digital-Analog-Wandler\cite{ESPCompare}\cite{ESP32}.\\ Einer der wichtigsten Unterschiede im Vergleich zur vorangegangenen Baureihe, dem ESP8266, ist die Ausführung vieler Modelle mit zwei Prozessorkernen. Verwendet werden Xtensa LX6, Xtensa LX7 oder RISC-V Prozessorkerne. Diese arbeiten mit Taktfrequenzen von \SI{160}{\mega\hertz} bzw. \SI{240}{\mega\hertz}. Für die optimale Ausnutzung der zwei Prozessorkerne bietet sich für die entsprechenden Modelle der Einsatz eines Echtzeit-Betriebssystems an. Das offizielle Entwicklungsframework der ESP32-Baureihe verwendet dazu FreeRTOS, ein weit verbreitetes Echtzeit-Betriebssystem\cite{Cameron2021}.\\ Die ESP32-Baureihe verfügt außerdem über eine Hardware-Beschleunigung für 32-Bit Gleitkommazahlen. Das bedeutet, dass arithmetische Operationen mit Gleitkommazahlen einfacher Genauigkeit nicht softwaretechnisch ausgeführt werden müssen. Es gibt einzelne Instruktionen, welche die Operationen direkt auf dafür entwickelter Hardware ausführen. Diese Hardware ist auch bei einem System mit zwei Prozessorkernen nur einfach ausgeführt. Die Hardware-Beschleunigung für Gleitkommaarithmetik muss klar einem Kern zugeordnet werden. Es ist zu empfehlen, alle Operationen der Gleitkommaarithmetik auf einem Prozessorkern auszuführen, um eine zeitintensive Umschaltung der Hardware zwischen den Prozessorkernen zu vermeiden. Die Hardware-Beschleunigung für Gleitkommaarithmetik ist nicht die schnellste am Markt verfügbare Ausführung\cite{ESPFloat}.

\subsection{Aufbau des Arbeitsspeichers}\label{subsec:Aufbau des Arbeitsspeichers}
    Da das Tensorflow Lite for Microcontrollers Framework die Daten eines Neuronalen Netzes im Arbeitsspeicher ablegt, ist es besonders wichtig, wie dieser bei der verwendeten Hardware aufgebaut ist. Wenn nicht bekannt ist, wie der Arbeitsspeicher der Hardware aufgebaut ist und welche Grenzen bei der Verwendung zu beachten sind, kann die Speicherung des Modells nicht sinnvoll angepasst werden. Die ESP32-Baureihe hat einen 32-Bit bzw. \SI{4}{GiB} Adressraum. Hierin befinden sich alle internen und externen Arbeits- und Flashspeicher. Auch Peripherieeinheiten sind teilweise innerhalb dieses Adressraums adressiert. Die ESP32-Baureihe ist in vier Serien, ESP32, ESP32-S2, ESP32-C3 und ESP32-S3 unterteilt, bei denen die Aufteilung und Adressierung des Arbeitsspeichers jeweils unterschiedlich erfolgt. Alle vier Serien verfügen über internen statischen Arbeitsspeicher. Außer der ESP32-C3 Serie verfügen alle über die Möglichkeit, externen Arbeitsspeicher in den Adressraum abzubilden. Die von Espressif vertriebenen Module verfügen, wenn unterstützt, meist schon über externen pseudostatischen Arbeitsspeicher. Die Größe des gleichzeitig in den Adressraum abbildbaren externen Arbeitsspeichers variiert zwischen den Serien. Der Adressraum wird sowohl vom Datenbus als auch vom Instruktionsbus genutzt. Somit handelt es sich wie beschrieben um eine modifizierte Harvard-Architektur. Der Arbeitsspeicher ist je nach Serie teilweise vom Datenbus, vom Instruktionsbus oder von beiden erreichbar\cite{ESPCompare}\ESPTDM.\\ Der interne statische Arbeitsspeicher der ursprünglichen ESP32 Serie hat eine Größe von \SI{520}{KiB} und ist in drei Sektionen unterteilt. Zwei dieser Sektionen sind durch den Datenbus erreichbar. Die andere Sektion kann nur durch den Instruktionsbus erreicht werden. Aus dieser Sektion kann ausführbarer Programmcode geladen werden. Der externe pseudostatische Arbeitsspeicher dieser Serie ist nur durch den Datenbus erreichbar. Die maximale Größe, welche gleichzeitig in den Adressraum abgebildet werden kann ist \SI{4}{MiB}\cite{ESP32}.\\ Der interne statische Arbeitsspeicher der ESP32-S2 Serie hat eine Größe von \SI{320}{KiB} und ist in zwei Sektionen unterteilt. Beide können sowohl durch den Datenbus als auch durch den Instruktionsbus angesprochen werden. In den Adressraum dieser Serie können gleichzeitig bis zu \SI{22}{MiB} externer pseudostatischer Arbeitsspeicher abgebildet werden. Die größte linear adressierte Sektion ist \SI{10,5}{MiB} groß. \SI{7,5}{MiB} des externen Arbeitsspeichers werden durch den Instruktionsbus angesprochen. Der Rest wird durch den Datenbus erreicht\cite{ESP32-S2}.\\ Die ESP32-C3 Serie verfügt wie bereits erwähnt nur über internen Arbeitsspeicher. Dieser hat eine Größe von \SI{400}{KiB} und ist in zwei Sektionen unterteilt. Eine Sektion ist nur durch den Instruktiosbus erreichbar, die andere ist durch den Instruktiosbus und durch den Datenbus erreichbar\cite{ESP32-C3}.\\ Der interne Arbeitsspeicher der ESP32-S3 Serie ist in drei Sektionen unterteilt. Die Gesamtgröße beträgt \SI{512}{KiB}. Jeweils eine der Sektionen ist nur durch einen der Busse erreichbar. Die dritte Sektion ist durch beide Busse erreichbar. Es kann externer Arbeitsspeicher einer Größe von \SI{32}{MiB} zeitgleich in den Adressraum abgebildet werden. Dieser kann entweder durch den Instruktiosbus oder durch den Datenbus erreicht werden. Der Speicher kann nur so konfiguriert werden, dass dieser jeweils durch einen der beiden Busse angesprochen wird. Ein Wechsel ist nicht ohne Weiteres möglich\cite{ESP32-S3}.\\ Darüber hinaus besteht die Möglichkeit, noch mehr externen Arbeitsspeicher zu verwenden. Die absoluten Grenzen für die Verwendung von diesem ist jeweils von der Serie abhängig. Da weiterer externer Arbeitsspeicher allerdings nicht gleichzeitig in den Adressraum abgebildet werden kann, muss dieser die vorgesehenen Adressen mit verwenden. Die Adressen im Adressraum verweisen dann je nach Konfiguration auf unterschiedliche physische Speicherbereiche. Dieser Mechanismus ist für einige Anwendungen geeignet um den nutzbaren Arbeitsspeicher zu vergrößern. Da für unterschiedliche physische Speicherbereiche dieselben Adressen verwendet werden, steigt die Größe des linear adressierbaren Speichers nicht. Für die Größe des linear adressierbaren Arbeitsspeichers sind also die oben genannten Größen für die jeweiligen Serien Maßgeblich\cite{ESPCompare}\ESPTDM. Der linear adressierbare Arbeitsspeicher ist eine Ressource, die für die Ausführung von Modellen mit Tensorflow Lite for Microcontrollers kritisch sein kann.

\subsection{Wirtschaftliche Faktoren}
    Die Produkte der ESP32-Baureihe sind gut verfügbar und besonders im Bereich IoT weit verbreitet. Der Hersteller Espressif hat Vertragshändler in Europa. Die Produkte werden zum größten Teil auf dem europäischen Markt vertrieben. Aufgrund von Lieferzeiten sind neue Produkte häufig zunächst nur in Asien und erst später in Europa verfügbar. Produkte, die erhältlich sind, werden über einen langen Zeitraum hinweg vertrieben. Auch ältere bzw. überholte Produktreihen sind noch käuflich erwerbbar. Es gibt aktuell kaum Berichte über eine Betroffenheit von Espressif Produkten von den Lieferengpässen bei Halbleitern. Trotz der Krise sind Espressif Produkte weiterhin verfügbar\cite{Oner2021}.\\ Modelle der ESP32-Baureihe finden nicht nur in serienmäßigen Lösungen ihre Anwendung, sondern werden auch oft für die Prototypentwicklung eingesetzt. Besonders im Bereich von IoT und Smart Home gibt es zahlreiche Anwendungsmöglichkeiten. Zusätzlich zum professionellen Support des Herstellers gibt es eine Reihe von Foreneinträgen und FAQs. Zusätzlich bietet die Firma Espressif verschiedenen Frameworks zur Entwicklung von Software für die vertriebenen Hardwarekomponenten. Diese werden weiterhin aktualisiert und durch den Hersteller weiterentwickelt. Das in dieser Arbeit verwendete IoT Development Framework ist Open-Source\cite{ESPIDF}.\\ Die Hardwarekosten sind im Vergleich zu Hardware, welche sonst für die Ausführung von Objekterkennungsmodellen verwendet wird, sehr gering. Auch im Bereich der Mikrocontroller zählen die meisten Modelle der ESP32-Baureihe zu den günstigeren Alternativen. Für die Verwendung von Mikrocontrollern der ESP32-Baureihe wird keine kostenpflichtige Software benötigt. Es stehen preiswerte Prototypmodelle inklusive externer Beschaltung, wie zum Beispiel externem Arbeitsspeicher zum Verkauf. Viele der Prototypmodelle werden direkt von Espressif hergestellt und von den Vertragshändlern vertrieben\cite{Oner2021}. 
    
\section{Aktueller Stand im Projekt SiGI}\label{sec:Aktueller Stand im Projekt SiGI}
    In diesem Kapitel wird der aktuelle Stand innerhalb des SiGI Projektes näher betrachtet. Speziell wird ein Fokus auf die Software zur Erfassung der Zählerstände gelegt.

\subsection{Entwicklung eines Prototyps}
    Aktuell befindet sich ein erster Prototyp des SiGI-Gerätes in der Entwicklungs- und Fertigungsphase. Wie bereits beschrieben, soll dieses Geräte in der Lage sein, analoge Strom- aber vor allem Gas- und Wasserzähler auszulesen. Der aktuelle Prototyp besteht aus einem Raspberry Pi inklusive Ethernet-Schnittstelle und einer Kamera. Mit Hilfe der Kamera werden Bilder der Anzeigeinstrumente der analogen Zähler gemacht. Diese Bilder werden dann durch den SiGI-Algorithmus verarbeitet, sodass die auf den Bildern dargestellten Zählerstände digital verfügbar sind. Über die Ethernet-Schnittstelle werden die so digitalisierten Daten an ein Backend weitergleitet.\\ Damit stellt SiGI die Basis für eine Reihe datenbasierter Geschäftsmodelle dar. Die Notwendigkeit eines solchen Gerätes ergibt sich aus der im Kapitel~\nameref{subsec:Smart Meter Rollout} beschriebenen Lücke bei der digitalen Erschließung von analogen Zählern. Um digitale, zählerdatenbasierte Geschäftsmodelle flächendeckend anbieten zu können, ist für aller Zählertypen eine praktische und kostengünstige Schnittstelle erforderlich. Der Grundgedanke hinter SiGI ist die Entwicklung eines generischen Interpreters, welcher für möglichst alle analogen Zählermodelle einsetzbar ist. Da alle analogen Zähler über eine für Menschen lesbare Anzeige verfügen, bietet diese die Möglichkeit eine plattformunabhängige, also generische Lösung zu entwickeln. Da das SiGI-Gerät nur Aufnahmen vom bereits vorhandenen Zähler machen muss und explizit für ältere Modelle entwickelt wurde, ist eine möglicherweise kostenintensive oder technisch aufwendige Anpassung der Messstelle innerhalb der Kundenanlage nicht notwendig. Das SiGI-Gerät wurde mit den Anforderungen, möglichst generisch einsetzbar und möglichst einfach installierbar zu sein, entwickelt.\\ Lediglich die Kosten des aktuellen Prototyps sind mit über \SI{100}{\euro} noch nicht optimal. Die hohen Kosten sind vor allem auf den Einsatz teurer Hardware zurückzuführen. Ließe sich der SiGI-Algorithmus auf einem Mikrocontroller in der Preisklasse eines günstigeren ESP32 realisieren, wird eine Senkung der Kosten um ca. \SI{75}{\euro} erwartet. Damit ließen sich die Beschaffungskosten des fertigen Produkts vermutlich auf ca. \SI{25}{\euro} reduzieren.

\subsection{Der SiGI Algorithmus}
    Herzstück des SiGI-Gerätes ist der SiGI-Algorithmus. Die Anforderungen an die Hardware des finalen Gerätes resultieren hauptsächlich aus den Anforderungen des Algorithmus. Die Rechenleistung des Gerätes muss von dem auf dem Gerät auszuführenden Programm abhängig gemacht werden. Auch ist es durchaus möglich, die Bestimmung des Zählerstandes nicht auf dem Gerät, sondern im Backend auf einem Server zu implementieren. Entsprechend würden die Anforderungen an die Rechenleistung sinken, während die ins Backend verschickte Datenmenge ansteigen würde. Welche der beiden Möglichkeiten verwendet wird, ist dabei von der Bandbreite der Schnittstelle abhängig.\\ Damit die Zählerstandserfassung von analogen Zählern möglichst unabhängig von der Art der eingesetzten Anzeigeinstrumente ist, muss der SiGI-Algorithmus möglichst generalisiert arbeiten. Maschinelle Lernverfahren bieten den Vorteil, dass sie die Muster innerhalb eines Datensatzes nicht nur erlernen sondern auch generalisieren\cite{Süße2014-2}. Eine gute Generalisierung der Muster zeigt sich, wenn die Erkennung der Muster auch auf während des Trainings unbekannten Daten erfolgreich ist. Die Neuronalen Netze der Tensorflow Object Detection API zeigen ein solches Verhalten. Der SiGI-Algorithmus basiert wesentlich auf einem mit dieser API entwickelten Modell, da für die Bildverarbeitung verwendbare Modelle bereits vortrainiert zur Verfügung stehen.\\ Das mit der Kamera aufgenommene Bild dient dem Objekterkennungsmodell als Merkmalsvektor. Wie im Kapitel~\nameref{subsec:Anwendungen in der Bildverarbeitung} beschrieben, werden mit Hilfe des Modells die Positionen von Ziffern bestimmt und klassifiziert. Anhand der Wahrscheinlichkeiten, mit denen das Modell Objekte klassifiziert, werden zunächst unplausible Ziffern herausgefiltert. Auch anhand der Größe und Form der Boxen um die detektierten Ziffern werden weitere herausgefiltert. Mit Hilfe der x-Koordinaten der Boxen werden die verbleibenden Ziffern gruppiert, da einzelne Ziffern fast immer mehrfach erkannt werden. Aus jeder Gruppe wird die Box mit der höchsten Wahrscheinlichkeit ausgewählt. Aus den Positionen der gewählten Ziffern wird dann ein Wert für den Zählerstand berechnet. Dieser Wert wird noch nicht direkt ans Backend verschickt. Zunächst wird abgewartet, bis elf Werte bestimmt wurden, um den Fehler zu korrigieren. Aus diesen elf Werten wird der Median gebildet. Bei korrekter Detektion ist immer der sechste Wert der Median. Gibt es eine Abweichung vom Wert zum Median, wird der Wert anhand dieser Abweichung korrigiert. Anhand der Größe der Abweichung wird die zu korrigierende Box bestimmt und angepasst. Dabei werden Ziffern  immer durch ihre jeweils ähnlichste Ziffer ersetzt. Je nach Vorzeichen resultiert aus der Änderung zusätzlich ein Übertrag zu einer anderen Stelle. Dieser Prozess wiederholt sich so oft, bis die Abweichung gleich null ist. Der so bestimmte Wert wird dann an das Backend verschickt.